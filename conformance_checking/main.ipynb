{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main notebook file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is the main file refered to by the README.md file. Execute the code chunks from top to bottom. Additional code chunks which will be labeled as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the functions (Package conformance checking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conformance_checking import (\n",
    "    throughput_time_to_xes,\n",
    "    create_alignment,\n",
    "    load_pnml, \n",
    "    make_dataframe_for_decision_tree,\n",
    "    save_alignments,\n",
    "    load_alignments,\n",
    "    clean_alignments,\n",
    "    generate_trace_encoding,\n",
    "    make_alignments_table,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: the computation step of the throughput time and converting it back to a XES format.\n",
    "The first step undertaken was the computation step of the throughput time and converting it back to a XES format. The function  *throughput_time_to_xes* in the python file *xes_to_csv.py* is responsible for this step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marijn\\Documents\\School\\Process Mining\\assignment\\conformance_checking\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "parsing log, completed traces :: 100%|██████████| 3093/3093 [00:08<00:00, 384.75it/s]\n",
      "exporting log, completed traces :: 100%|██████████| 3093/3093 [00:11<00:00, 269.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event log has been successfully exported to XES format!\n"
     ]
    }
   ],
   "source": [
    "throughput_time_to_xes(\"data/BPI2017Denied(3).xes\",\"data/BPI2017Denied(3).csv\",\"data/BPI2017Denied(3)_Throughput.xes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:  loading the normative process model (PetriNet).\n",
    "The second step is loading the normative process model (PetriNet). The PetriNet given *BPI2017Denied_PetriNet.pmnl* is loaded in and visualized with the function *load_pnml* in the python file *alignment.py*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PetriNet, iMarking, fMarking = load_pnml(\"data/BPI2017Denied_petriNet.pnml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: the generation of the alignments for each trace in the event log.\n",
    "The third step undertaken was the generation of the alignments for each trace in the event log. After the eventlog and the normative process model are loaded the function *create_alignment.py* will create the optimal alignments with the event log and PetriNet as parameters. The alignments can also be saved as a .pkl file with the function *save_alignment* in the *alignment.py* python file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments = create_alignment(\"data/BPI2017Denied(3)_Throughput.xes\", PetriNet, iMarking, fMarking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional: Saving the alignments as a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_alignments(alignments, 'data/alignments.pkl')\n",
    "alignments = load_alignments('data/alignments.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning step\n",
    "Before applying a decision tree can be applied on the alignments, they have to be cleaned and encoded. The function clean_alignment in the python file *create_alignment.py* replaces the silent activity model move and log move *((none, >>) and (>>,none))* with a τ for additional readability and interpretability in the decision tree regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_alignments = clean_alignments(alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding step\n",
    "The encoding step is undertaken with the functions *generate_trace_encoding* and *make_dataframe_for_decision_tree* both in the *create_alignment.py* python file. The *generate_trace_encoding* counts and aggregates all alignments on a trace level with one-hot encoding. *make_dataframe_for_decision_tree* adds the troughput time per trace and converts the object into a csv file for the decision tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_count_per_trace = generate_trace_encoding(clean_alignments)\n",
    "make_dataframe_for_decision_tree(\"data/BPI2017Denied(3)_Throughput.xes\", move_count_per_trace, 'data/df_with_tau_for_decision_tree.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional: View alignment in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_alignments_table(clean_alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional: Vizualize Both PetriNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The given PetriNet (petrinet_graphs/given_petrinet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![given_Petrinets](petrinet_graphs/given_petrinet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The mined PetriNet (Based on the event log; (petrinet_graphs/mined_petrinet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mined_Petrinets](petrinet_graphs/mined_petrinet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: The application of the set of encoded traces on a decision tree algorithm.\n",
    "The fourth step is the application of the set of encoded traces on a decision tree algorithm. The decision tree regressor algorithm can be found in **NAME.ipynb**. Hyperparameter optimalization trough gridsearch cross validation is being utilized to enhance the overall performance of the decision tree regressor algorithm. The final hyperparameters can be found in a configuration file named: **config.json**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Deriving Classification rules\n",
    "Finally, the classification rules derived from the decision tree are produced with the function **NAME** in python file **NAME.py**. This function traverses through the derived decision tree and returns the classification rules and the amount of traces that apply for each classification rule in a csv. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
